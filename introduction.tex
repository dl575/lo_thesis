\chapter{Introduction}
\label{chap:intro}

\section{Secure and Reliable Hardware Architectures for Real-Time Systems}
\label{sec:intro.security}

% Run-time monitoring is useful
Run-time monitoring techniques have been shown to be useful for improving the
reliability, security, and debugging capabilities of computer systems. For
example, Hardbound is a hardware-assisted technique to detect out-of-bound
memory accesses, which can cause undesired behavior or create a security
vulnerability if uncaught \cite{hardbound-asplos08}. Intel has recently
announced plans to support buffer overflow protection similar to Hardbound in
future architectures \cite{intel-mpx}. Similarly, run-time monitoring can
enable many other new security, reliability, and debugging capabilities such as
fine-grained memory protection \cite{mondrian-asplos02}, information flow
tracking \cite{dift-asplos04, testudo-micro08}, hardware error detection
\cite{argus-micro07}, data-race detection \cite{radish-isca12, cord-hpca06},
etc.  However, today's parallel monitoring techniques cannot be easily applied
to critical real-time systems due to their lack of timing guarantees. Thus, we
have developed several techniques in order to enable run-time monitoring on
real-time systems.

% Monitoring WCET
First, we developed a static analysis method to estimate the worst-case
execution time (WCET) impact of run-time monitoring for real-time systems
(Chapter~\ref{chap:monitoring_wcet}). This was done by extending the
traditional integer-linear programming (ILP) formulation used for estimating
WCET by adding new constraints in order to model the impact of run-time
monitoring.

% Monitoring Hard Drop
In our experiments, we found that the WCET of run-time monitoring can be high.
Thus, applying monitoring to real-time systems requires a large increase in the
time allocated to tasks. Currently, if a real-time system cannot support this
extra utilization, then monitoring cannot be applied to the system.  Thus, we
developed a hardware architecture that selectively performs monitoring in order
to meet given timing constraints (Chapter~\ref{chap:monitoring_hard_drop}).
This is possible by taking advantage of the dynamic slack that exists between
average-case and worst-case performance.

% Monitoring Soft Drop
Soft real-time and interactive systems do not require strict timing guarantees
but still look to achieve timely execution of programs. Thus, by building on
our work in applying monitoring to hard real-time systems, we created an
architecture that enables a trade-off between overheads and monitoring coverage
(Chapter~\ref{chap:monitoring_dift_drop}). 

\section{Energy-Efficient Hardware Architectures for Real-Time Systems}
\label{sec:intro.energy}

For modern mobile and embedded systems, energy usage is a major concern due to
limited battery life. Energy is also an important concern for servers and
datacenters due to their significant contribution to operating costs.
Techniques, such as dynamic frequency and voltage scaling (DVFS) and
heterogeneous core mixes, have been developed to enable a trade off between
power and performance. These resource allocation techniques can be used to
reduce energy usage at the cost of increased execution time.

Traditional managers for these resource allocation techniques, such as DVFS,
work in a best effort manner. They operate under the assumption that better
performance is typically better and only attempt to decrease resources when the
performance impact is minimal.  However, many applications or jobs have
response-time requirements.  Finishing faster than this response-time
requirement has no benefit. For example, responding to a user input faster than
human reaction time does not improve user experience. Similarly, decoding video
frames faster than the video frame rate has no added benefit. In this thesis,
we propose to apply resource management techniques, such as DVFS, while taking
into account response-time requirements in order to save energy with minimal or
no impact on user experience.

There are several existing projects which have looked into the problem of
resource management in the presence of timing requirements. One possible
solution is to use DVFS in conjunction with a real-time operating system (RTOS)
\cite{rtdvfs-systor12}. This is useful for hard real-time systems where timing
requirements are strict. However, it requires considerable programmer expertise
and effort in order to write applications in a form that is amenable to an RTOS
and to perform the detailed timing analysis required. For soft real-time
systems, such as the response-time requirements we are considering, it should
be possible to use a more lightweight approach to handle the timing
requirements. Zhu and Reddi \cite{zhu-hpca13} explored using DVFS and
heterogeneous cores in order to lower energy usage while still meeting website
loading times for a web browser. This was done by analyzing the relationship of
various HTML and CSS metrics to loading time. They showed a 9\% average
reduction in energy usage by using this information when selecting core and
DVFS operating point compared to an OS scheduler that uses only utilization
information.  However, their approach is specific to web browsing and does not
generalize to other applications. PACORA \cite{pacora-hotpar11} looks at
resource partitioning for datacenters while taking into account response-time
requirements. It can dynamically alter these allocations but these are done on
a course-grained level in order to detect changes in workload behavior rather
than on a fine-grained per-job level. Recent work has shown that timing on a
job-to-job basis can have large variations \cite{atlas-rtas13} and that
fine-grained resource allocations can have a high impact on energy efficiency
that is not captured by coarse-grained allocations \cite{padmanabha-micro13}.

Given the previous work in this domain, our approach is unique in targeting the
combination of several design objectives:
\begin{enumerate}
  \item \textbf{Generality: } The approach should work generally for any
  application with response-time requirements. It should not require
  application- or domain-specific knowledge.
  \item \textbf{Minimal programmer effort: } The additional programmer effort
  in order to enable this should be minimal. The only needed information from
  the programmer is the code segments of interest and their response-time
  requirement.
  \item \textbf{Fine-grained decision: } The resource allocation decision
  should be made on a per-job basis in order to handle job-to-job variation.
  For example, recent work has shown that video decoding time can vary greatly
  from frame-to-frame \cite{atlas-rtas13}. 
  \item \textbf{Predictive decision: } Our approach looks to predict resource
  allocations before a job is run. Since execution times can change largely
  from job to job, it is important to predict the execution time for the next
  job to run, rather than making decisions after poor response-time performance
  is seen.
\end{enumerate}

As an initial study in designing such a system, we are attempting to use
machine learning techniques in order to predict whether the execution time of a
dynamic instance of a job is greater than or less than a response-time
threshold. If the job is predicted to take longer than the response-time
requirement, then resources should be increased in order to make the deadline.
In order to make this prediction, we use the values of variables used in
control flow decisions and as function arguments as these, intuitively, will
have the most impact on execution time. In order to test the predictive power
of this information, we have used a support vector machine (SVM) to predict
execution time using this data. Initial results have shown accuracies of
67\%-100\% depending on the response-time requirement. This is a promising
start to our goal of developing an architecture that automatically takes
advantage of response-time requirements in order to save energy through dynamic
resource allocation.

